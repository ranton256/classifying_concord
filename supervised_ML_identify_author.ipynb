{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranton256/classifying_concord/blob/main/supervised_ML_identify_author.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s83V3g2C7nxd"
      },
      "source": [
        "# Supervised Machine Learning - Identify Author\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h9auqnt97mAC"
      },
      "outputs": [],
      "source": [
        "!pip install -q spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BElbDhze09kt"
      },
      "outputs": [],
      "source": [
        "# you will need to download the spacy model for english.\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlBdBTzO09kt"
      },
      "outputs": [],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H08DAVhw09ku"
      },
      "outputs": [],
      "source": [
        "# %pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWnxmtm27-R-"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMEXAMxx9mnH"
      },
      "source": [
        "## The Dataset\n",
        "Our two datasets are constructed from two related works of 19th century American transcendentalism. These are both public domain.\n",
        "\n",
        "1. [Essays by Ralph Waldo Emerson by Ralph Waldo Emerson](https://www.google.com/url?q=https%3A%2F%2Fwww.gutenberg.org%2Febooks%2F16643)\n",
        "2. [Walden, and On The Duty Of Civil Disobedience by Henry David Thoreau](https://www.google.com/url?q=https%3A%2F%2Fwww.gutenberg.org%2Febooks%2F205)\n",
        "\n",
        "These two authors had different writing styles but shared more than their philosophical interestsâ€”they were neighbors in Concord, Massachusetts.\n",
        "\n",
        "These two works are also similar in length when formatted as plain text.\n",
        "\n",
        "We will use spaCy to segment each work into sections of roughly 3 to 5 sentences each, then build a datafrom of the text including a label of 'emerson' or 'thoreau', then shuffle and split that into train and test sets for training some machine learning models to classify them by predicting which author they are from and compare the results.\n",
        "\n",
        "We will also preprocess text to remove stopwords,and perform lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w8gE7J69mSM"
      },
      "outputs": [],
      "source": [
        "emerson_txt_url = \"https://www.gutenberg.org/ebooks/16643.txt.utf-8\"\n",
        "thoreau_txt_url = \"https://www.gutenberg.org/ebooks/205.txt.utf-8\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0biGW34-Y2v"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6A15umWC-EE"
      },
      "outputs": [],
      "source": [
        "def download_file(url):\n",
        "  local_filename = Path(url.split('/')[-1])\n",
        "  result = requests.get(url)\n",
        "  result.raise_for_status()\n",
        "  with open(local_filename, \"wb\") as f:\n",
        "      f.write(result.content)\n",
        "  return local_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMnksRH2-77l"
      },
      "outputs": [],
      "source": [
        "emerson_file = download_file(emerson_txt_url)\n",
        "thoreau_file = download_file(thoreau_txt_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smcU9xj8-rqA"
      },
      "outputs": [],
      "source": [
        "!head -n 50 {emerson_file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U7mU_eo-t8A"
      },
      "outputs": [],
      "source": [
        "!head -n 50 {thoreau_file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E0aLB46S_ys"
      },
      "outputs": [],
      "source": [
        "# Let's strip the frontmatter lines off the start of each file.\n",
        "# remove each line preceding one that contains \"START OF THE PROJECT GUTENBERG EBOOK \"\n",
        "!grep -n \"START OF THE PROJECT GUTENBERG EBOOK\" {emerson_file}\n",
        "!grep -n \"START OF THE PROJECT GUTENBERG EBOOK\" {thoreau_file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFX9IDG-Tfr2"
      },
      "outputs": [],
      "source": [
        "def trim_frontmatter(filename):\n",
        "  with open(filename) as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "  n_trim_lines = 0\n",
        "  for i, line in enumerate(lines):\n",
        "    if \"START OF THE PROJECT GUTENBERG EBOOK\" in line:\n",
        "      n_trim_lines = i + 1\n",
        "      break\n",
        "\n",
        "  trimmed_lines = lines[n_trim_lines:]\n",
        "  trimmed_content = '\\n'.join(trimmed_lines)\n",
        "  new_filename = f\"trimmed_{filename}\"\n",
        "  with open(new_filename, \"w\") as f:\n",
        "    f.write(trimmed_content)\n",
        "  return new_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrvGsmN6T717"
      },
      "outputs": [],
      "source": [
        "trimmed_emerson_file = trim_frontmatter(emerson_file)\n",
        "trimmed_thoreau_file = trim_frontmatter(thoreau_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFSTJY-dUDAe"
      },
      "outputs": [],
      "source": [
        "!head {trimmed_emerson_file}\n",
        "!head {trimmed_thoreau_file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqIq3-IKBAzW"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "from random import randint\n",
        "import itertools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx67k0r0DG_i"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# if you have an error here, make sure you ran the \"!python -m spacy download en_core_web_sm\" command in the earlier cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrKOQs8y_cYW"
      },
      "outputs": [],
      "source": [
        "def segment_doc(filename):\n",
        "  with open(filename) as f:\n",
        "    text = f.read()\n",
        "  doc = nlp(text)\n",
        "  assert doc.has_annotation(\"SENT_START\")\n",
        "\n",
        "  sent_dq = deque()\n",
        "  #it = doc.sents.__iter__()\n",
        "  n = randint(3, 5)\n",
        "\n",
        "  for sent in doc.sents:\n",
        "    sent_dq.append(sent)\n",
        "    if len(sent_dq) > n:\n",
        "      sent_dq.popleft()\n",
        "      snippet = \" \".join(sent.text for sent in sent_dq)\n",
        "      yield snippet\n",
        "      n = randint(3, 5)\n",
        "      sent_dq.clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60_UJ2_XD0U-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSb3R9uQ_EJb"
      },
      "outputs": [],
      "source": [
        "def dataframe_from_file(file_path):\n",
        "  segments = segment_doc(file_path)\n",
        "\n",
        "  df = pd.DataFrame(segments, columns=[\"text\"])\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vE5Lc8OGNx-"
      },
      "outputs": [],
      "source": [
        "emerson_df = dataframe_from_file(trimmed_emerson_file)\n",
        "emerson_df.to_csv(\"emerson.csv\")\n",
        "emerson_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgmr6GUCHNz7"
      },
      "outputs": [],
      "source": [
        "emerson_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbbwfB3OGZFj"
      },
      "outputs": [],
      "source": [
        "\n",
        "thoreau_df = dataframe_from_file(trimmed_thoreau_file)\n",
        "thoreau_df.to_csv(\"thoreau.csv\")\n",
        "thoreau_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH_UfKPYHKXW"
      },
      "outputs": [],
      "source": [
        "thoreau_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MgxMVJJGuji"
      },
      "outputs": [],
      "source": [
        "# combine and shuffle the datasets, using a consistent random seed.\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "d1 = emerson_df.copy()\n",
        "d1[\"label\"] = \"emerson\"\n",
        "\n",
        "d2 = thoreau_df.copy()\n",
        "d2[\"label\"] = \"thoreau\"\n",
        "\n",
        "combined_df = pd.concat([d1, d2])\n",
        "combined_df = shuffle(combined_df, random_state=7919)\n",
        "combined_df.to_csv(\"combined.csv\")\n",
        "combined_df.info()\n",
        "combined_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU9cPIMIIVqV"
      },
      "source": [
        "## Now we have our dataset in combined.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86xbNRNVJ2Jv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9QoczEkGoD_"
      },
      "outputs": [],
      "source": [
        "# you can start here if csv files were already created.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAH5Q5ouJvoW"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=combined_df[\"label\"], palette=\"rocket\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUkDsv3mS7_c"
      },
      "outputs": [],
      "source": [
        "%pip install -q wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hdFyqp7Toa3"
      },
      "outputs": [],
      "source": [
        "from spacy.lang.en import STOP_WORDS\n",
        "my_stopwords = STOP_WORDS\n",
        "\n",
        "', '.join(my_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKSo5E_WmEOR"
      },
      "outputs": [],
      "source": [
        "# Show wordcloud from each dataset.\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "\n",
        "def plot_word_cloud(text_sections, title):\n",
        "  cloud = WordCloud(background_color='black', stopwords=my_stopwords).generate(str(text_sections))\n",
        "  fig = plt.figure(figsize=(12,8), facecolor='white')\n",
        "  plt.imshow(cloud, interpolation=\"bilinear\")\n",
        "  plt.axis('off')\n",
        "  plt.title(title, fontsize=48)\n",
        "  plt.tight_layout(pad=0)\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UWDYeVWS-6A"
      },
      "outputs": [],
      "source": [
        "plot_word_cloud(emerson_df[\"text\"], \"Emerson\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnAlz6ogTdH8"
      },
      "outputs": [],
      "source": [
        "plot_word_cloud(thoreau_df[\"text\"], \"Thoreau\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0x9cqGq_9tDR"
      },
      "outputs": [],
      "source": [
        "# Preprocess text to remove stopwords, and perform lemmatization.\n",
        "\n",
        "final_text = []\n",
        "for index,entry in enumerate(combined_df['text']):\n",
        "  doc = nlp(entry.lower())\n",
        "  Final_words = []\n",
        "  for word in doc:\n",
        "    if not word.is_stop and not word.is_punct:\n",
        "      Final_words.append(word.lemma_)\n",
        "  final_text.append(' '.join(Final_words))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBR-ubODAcf_"
      },
      "outputs": [],
      "source": [
        "combined_df['final_text'] = final_text\n",
        "combined_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNu7ZEcRJjN4"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(combined_df[\"final_text\"])\n",
        "y = combined_df[\"label\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMWFWbCrJ32k"
      },
      "outputs": [],
      "source": [
        "# split our data into train and test sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4909)\n",
        "print(f\"x_train: {x_train.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"x_test: {x_test.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvT7xANVJj1r"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1httoB19K8UB"
      },
      "outputs": [],
      "source": [
        "# -2 for n_jobs is all but one CPU available.\n",
        "lr_model = LogisticRegression(solver='saga', random_state=8102, n_jobs=-2)\n",
        "\n",
        "lr_model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKsOun07mKZ5"
      },
      "outputs": [],
      "source": [
        "y_pred = lr_model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-6EqVCZ09ky"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us_nG_jrl2A5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def show_metrics(y_test, y_pred, model_name):\n",
        "  display(Markdown(f\"# {model_name}\"))\n",
        "\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  print(\"Test accuracy:\", accuracy_score(y_test,y_pred))\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  labels = [\"emerson\", \"thoreau\"]\n",
        "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.ylabel('Actual')\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNgvmWyjQR-N"
      },
      "outputs": [],
      "source": [
        "show_metrics(y_test, y_pred, \"Logistic Regression\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK3RPYr0meGE"
      },
      "outputs": [],
      "source": [
        "# Let's compare that to random forests.\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzyXfA9Lsh0D"
      },
      "outputs": [],
      "source": [
        "y_pred_rf = rf.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2YCAfxdQeUH"
      },
      "outputs": [],
      "source": [
        "show_metrics(y_test, y_pred_rf, \"Random Forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsyCbx799Sx5"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvKHe5JzOfiX"
      },
      "outputs": [],
      "source": [
        "# create the SVM classifier\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdIx7kAr9R2Z"
      },
      "outputs": [],
      "source": [
        "y_pred_svm = clf.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGf0QqRkQmsN"
      },
      "outputs": [],
      "source": [
        "show_metrics(y_test, y_pred_svm, \"SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTnzUHcps9SH"
      },
      "outputs": [],
      "source": [
        "%pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJXwL_5409ky"
      },
      "outputs": [],
      "source": [
        "%pip install -q torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPQFoOL0uLlH"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Aa2PJ55uOW6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMMOQVRwuTGg"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", return_token_type_ids = False, padding=\"max_length\", truncation=True)\n",
        "\n",
        "model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OYugrXv0-53"
      },
      "outputs": [],
      "source": [
        "x_train_s, x_test_s, y_train_s, y_test_s = train_test_split(combined_df[\"text\"], combined_df[\"label\"], test_size=0.2, random_state=4909)\n",
        "print(f\"x_train_s: {x_train_s.shape}\")\n",
        "print(f\"y_train_s: {y_train_s.shape}\")\n",
        "print(f\"x_test_s: {x_test_s.shape}\")\n",
        "print(f\"y_test_s: {y_test_s.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-cuowWt0v88"
      },
      "outputs": [],
      "source": [
        "x_train_tok = tokenizer(x_train_s.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "y_train_tok = y_train_s.tolist()\n",
        "\n",
        "x_test_tok = tokenizer(x_test_s.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "y_test_tok = y_test_s.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tRjtAKyvvch"
      },
      "outputs": [],
      "source": [
        "x_train_tok[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRZEna3n0je_"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(x_train_tok.keys())\n",
        "\n",
        "\n",
        "#move onto device (GPU)\n",
        "x_train_tok = {k:torch.tensor(v).to(device) for k,v in x_train_tok.items()}\n",
        "x_test_tok = {k:torch.tensor(v).to(device) for k,v in x_test_tok.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdt0N4Lp2jBU"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  hidden_train = model(**x_train_tok)\n",
        "  hidden_test = model(**x_test_tok)\n",
        "\n",
        "# Get the [CLS] hidden states\n",
        "cls_train = hidden_train.last_hidden_state[:,0,:]\n",
        "cls_test = hidden_test.last_hidden_state[:,0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LTo1mgL3AFW"
      },
      "outputs": [],
      "source": [
        "x_train_db = cls_train.to(\"cpu\")\n",
        "# y_train_tok\n",
        "\n",
        "x_test_db = cls_test.to(\"cpu\")\n",
        "# y_test_tok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nktP6Uv7XPM"
      },
      "outputs": [],
      "source": [
        "lr_model2 = LogisticRegression(C=1, solver='saga', random_state=8102, n_jobs=-2, max_iter=10_000)\n",
        "\n",
        "lr_model2.fit(x_train_db,y_train_tok)\n",
        "\n",
        "# This does not converge, with the settings used for TF-DF\n",
        "# ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
        "# So we adjusting max_iter and experimented with C (regulation strength).\n",
        "\n",
        "y_pred = lr_model2.predict(x_test_db)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7A9a3NvQypG"
      },
      "outputs": [],
      "source": [
        "show_metrics(y_test_tok, y_pred, \"Logistic Regression on DistilBERT hidden states\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUv5zKW76g43"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train_db,y_train_tok)\n",
        "\n",
        "rf.score(x_test_db,y_test_tok)\n",
        "\n",
        "y_pred_rf = rf.predict(x_test_db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw7_Koo7RBw2"
      },
      "outputs": [],
      "source": [
        "show_metrics(y_test_tok, y_pred_rf, \"Random Forest on DistilBERT hidden states\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q89XJ3cY8Qmj"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRoC6iQs8pDp"
      },
      "outputs": [],
      "source": [
        "# create the SVM classifier\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "\n",
        "clf.fit(x_train_db,y_train_tok)\n",
        "\n",
        "y_pred_svm = clf.predict(x_test_db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb0_XDXt849Z"
      },
      "outputs": [],
      "source": [
        "show_metrics(y_test_tok, y_pred_svm, \"SVM on DistilBERT hidden states\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaJ6eWuAX9Gs"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "# Define the model with random weights, suitable for binary classification (2 classes)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased', num_labels=2\n",
        ")\n",
        "# we already have the appropriate tokenizer from before.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Gvc11-YI45"
      },
      "outputs": [],
      "source": [
        "# create our optimizer\n",
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XQP-euxZjKO"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFiWLJWCaUcY"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Create a copy of our dataframe\n",
        "trans_df = combined_df.copy()\n",
        "\n",
        "# drop the preprocessed text column which we aren't using.\n",
        "trans_df.drop(\"final_text\", axis=1, inplace=True)\n",
        "\n",
        "# transform our labels into numeric values.\n",
        "le = preprocessing.LabelEncoder()\n",
        "my_labels = trans_df[\"label\"].tolist()\n",
        "le.fit(my_labels)\n",
        "\n",
        "my_cat_labels = le.classes_\n",
        "trans_df[\"label\"] = le.transform(trans_df[\"label\"])\n",
        "\n",
        "print(f\"{my_cat_labels=}\")\n",
        "\n",
        "trans_df.info()\n",
        "trans_df.describe()\n",
        "trans_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F_O_eOBZZTy"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# for simplicity, we are just splitting the dataset again.\n",
        "train_df, test_df = train_test_split(trans_df, test_size=0.2, random_state=4909)\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "def tokenize_data(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_data, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_data, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGRPftNjYPKH"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    # this parameter was apparently removed recently.\n",
        "    # evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Define Trainer object for training the model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92_Rh6CFc1zd"
      },
      "outputs": [],
      "source": [
        "# Save the model.\n",
        "trainer.save_model('model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdeKS9fVgK1S"
      },
      "outputs": [],
      "source": [
        "# This is how you can load the model.\n",
        "\n",
        "# from transformers import AutoModelForSequenceClassification\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"./model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEAi4v5YedwK"
      },
      "outputs": [],
      "source": [
        "def predictor(text):\n",
        "  #inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "  inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "  inputs = {k:torch.tensor(v).to(device) for k,v in inputs.items()}\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = model(**inputs).logits\n",
        "  predictions = torch.argmax(logits, dim=-1)\n",
        "  return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D2kOWOTg_wa"
      },
      "outputs": [],
      "source": [
        "x_test_trans = test_dataset[\"text\"]\n",
        "y_test_trans = test_dataset[\"label\"]\n",
        "\n",
        "# sanity test a few inference inputs.\n",
        "for txt, lbl in zip(x_test_trans[:5], y_test_trans[:5]):\n",
        "  pred = predictor( txt)\n",
        "  print(f\"{my_cat_labels[lbl]}: pred={my_cat_labels[pred]}, {txt=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qky-ilsd8_s"
      },
      "outputs": [],
      "source": [
        "y_pred_trans = [predictor(txt) for txt in x_test_trans]\n",
        "\n",
        "for txt, lbl, pred in zip(x_test_trans[:5], y_test_trans[:5], y_pred_trans[:5]):\n",
        "  print(f\"{my_cat_labels[lbl]}: pred={my_cat_labels[pred]}, {txt=}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQkZP2HREOA3"
      },
      "outputs": [],
      "source": [
        "y_pred_trans = [torch.tensor(v).cpu() for v in y_pred_trans]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX8ZTX4PD4MS"
      },
      "outputs": [],
      "source": [
        "y_test_trans = [torch.tensor(v).cpu() for v in y_test_trans]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-f2-1Fp9ch8"
      },
      "outputs": [],
      "source": [
        "show_metrics(y_pred_trans, y_test_trans, \"Fine-tuned DistilBERT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09RtrdlMPZWJ"
      },
      "source": [
        "## Let's check out the test samples that are misclassified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWMW5hXrQqPU"
      },
      "outputs": [],
      "source": [
        "def scalar_from_tensor(t):\n",
        "  if t.dim() == 0:\n",
        "    return t.item()\n",
        "  elif t.dim() == 1:\n",
        "    return t[0].item()\n",
        "  else:\n",
        "    raise ValueError(f\"Unexpected tensor dimension: {t.dim()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZw_0dDhRWc0"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_test_trans = [scalar_from_tensor(t) for t in y_test_trans]\n",
        "y_pred_trans = [scalar_from_tensor(t) for t in y_pred_trans]\n",
        "\n",
        "print(f\"y_test_trans: {y_test_trans[:5]}\")\n",
        "print(f\"y_pred_trans: {y_pred_trans[:5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvsE-J0q986E"
      },
      "outputs": [],
      "source": [
        "print(\"my_cat_labels\")\n",
        "\n",
        "rows = []\n",
        "for i, (txt, lbl, pred) in enumerate(zip(x_test_trans, y_test_trans, y_pred_trans)):\n",
        "  if lbl != pred:\n",
        "    print(f\"{lbl=},{pred=}\")\n",
        "    row =(my_cat_labels[lbl], my_cat_labels[pred], txt)\n",
        "    print(f\"{row=}\")\n",
        "    rows.append(row)\n",
        "\n",
        "n_miss = len(rows)\n",
        "print(f\"Count of misclassified = {n_miss}\")\n",
        "misclassified_df = pd.DataFrame(rows, columns=[\"actual\", \"predicted\", \"text\"])\n",
        "misclassified_df.head(n_miss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue3LYUKw09k3"
      },
      "source": [
        "## Postscript - Few short learning with a modern LLM\n",
        "\n",
        "Another technique that is used recently is to use a few-shot learning to inject examples as context into an existing LLM model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31WhjRofPg0w"
      },
      "outputs": [],
      "source": [
        "# choose some examples of each author from our training set.\n",
        "import re\n",
        "\n",
        "training_df = combined_df.copy()\n",
        "\n",
        "few_shot_num_examples = 10\n",
        "\n",
        "thoreau_samples = training_df[ training_df[\"label\"] == \"thoreau\"].sample(few_shot_num_examples, random_state=7809)\n",
        "emerson_samples = training_df[ training_df[\"label\"] == \"emerson\"].sample(few_shot_num_examples, random_state=997)\n",
        "\n",
        "# remove the training samples.\n",
        "training_df.drop(thoreau_samples.index, axis=0, inplace=True)\n",
        "training_df.drop(emerson_samples.index, axis=0, inplace=True)\n",
        "\n",
        "# print(f\"Thoreau sample: {thoreau_samples}\")\n",
        "# print(f\"Emerson sample: {emerson_samples}\")\n",
        "\n",
        "emerson_samples_array = emerson_samples['text'].to_list()\n",
        "thoreau_samples_array = thoreau_samples['text'].to_list()\n",
        "\n",
        "emerson_samples_array = [s.strip() for s in emerson_samples_array]\n",
        "thoreau_samples_array = [s.strip() for s in thoreau_samples_array]\n",
        "\n",
        "# replace multiple newlines with a single newline\n",
        "emerson_samples_array = [re.sub(r'\\n+', '\\n', sample) for sample in emerson_samples_array]\n",
        "thoreau_samples_array = [re.sub(r'\\n+', '\\n', sample) for sample in thoreau_samples_array]\n",
        "\n",
        "print(\"======Emerson samples:======\\n\")\n",
        "for idx, sample in enumerate(emerson_samples_array):\n",
        "    print(f\"{idx+1}: {sample}\\n\")\n",
        "\n",
        "print(\"======Thoreau samples:======\\n\")\n",
        "for idx, sample in enumerate(thoreau_samples_array):\n",
        "    print(f\"{idx+1}: {sample}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ij5FLkq09k3"
      },
      "outputs": [],
      "source": [
        "# We also need our prompt template\n",
        "prompt_template = \"\"\"\n",
        "You are an expert literary analyst. Your task is to classify whether a given text was written by {author1} or {author2}.\n",
        "\n",
        "Here are some example texts from each author:\n",
        "\n",
        "{author1} examples:\n",
        "{author1_examples}\n",
        "\n",
        "{author2} examples:\n",
        "{author2_examples}\n",
        "\n",
        "Based on these examples and your knowledge of their writing styles, analyze the following text and determine whether it was written by {author1} or {author2}:\n",
        "\n",
        "Text to classify:\n",
        "{text_to_classify}\n",
        "\n",
        "Provide your classification as either {author1} or {author2}.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV7LKtT909k3"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(text, author1, author2):\n",
        "    prompt_text = prompt_template.format(author1=author1, author2=author2, author1_examples=emerson_samples_array, author2_examples=thoreau_samples_array, text_to_classify=text)\n",
        "    return prompt_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z2jKnVZ09k3"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Now that we have our samples, we can inject them into an LLM.\n",
        "# we will use Hugging Face's transformers library to inject the samples into the model.\n",
        "\n",
        "\n",
        "# this model is small but accepts longer input sequences than BERT/DistilBERT.\n",
        "#model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "# model_name = \"roberta-large\"\n",
        "model_name = \"answerdotai/ModernBERT-base\"\n",
        "\n",
        "dev_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(dev_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    id2label={0: \"emerson\", 1: \"thoreau\"},\n",
        "    label2id={\"emerson\": 0, \"thoreau\": 1}\n",
        "    ).to(device)\n",
        "\n",
        "# get the tokenizer for the model.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0efLgy_E09k4"
      },
      "outputs": [],
      "source": [
        "# Use the model to predict the samples.\n",
        "import torch\n",
        "\n",
        "def classify_text(text, author1, author2):\n",
        "    prompt_text = generate_prompt(text, author1, author2)\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
        "    inputs = {k:torch.tensor(v).to(device) for k,v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_id = logits.argmax().item()\n",
        "\n",
        "    output_logits = outputs.logits\n",
        "    predicted_class_id = torch.argmax(output_logits, dim=1).item()\n",
        "    predicted_class_label = model.config.id2label[predicted_class_id]\n",
        "    predicted_probability = torch.softmax(output_logits, dim=1).max().item()\n",
        "\n",
        "    return predicted_class_label, predicted_probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEkxJx9I09k4"
      },
      "outputs": [],
      "source": [
        "# let's try a few examples.\n",
        "\n",
        "samples = training_df.sample(3, random_state=4909)\n",
        "\n",
        "for cnt, (idx, sample) in enumerate(samples.iterrows()):\n",
        "    print(f\"Example {cnt+1}:\")\n",
        "    print(f\"Text: {sample['text']}\")\n",
        "    predicted_label, predicted_probability = classify_text(sample['text'], \"Emerson\", \"Thoreau\")\n",
        "    print(f\"Prediction: {predicted_label} ({predicted_probability:.2f})\")\n",
        "    print(f\"Actual: {sample['label']}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJCD4dCl09k4"
      },
      "outputs": [],
      "source": [
        "%pip install -q tqdm\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaF00zz-09k4"
      },
      "outputs": [],
      "source": [
        "#A run over the whole dataset\n",
        "\n",
        "# since we haven't trained the model, we don't really need to split the dataset.\n",
        "\n",
        "MAX_SAMPLES = 100  # 100 samples is enough to get a good idea of the performance.\n",
        "\n",
        "texts = training_df[\"text\"].tolist()\n",
        "y_actual_phi = training_df[\"label\"].tolist()\n",
        "\n",
        "\n",
        "# use tqdm to show progress\n",
        "y_pred_phi = [classify_text(text, \"Emerson\", \"Thoreau\")[0] for text in tqdm(texts[:MAX_SAMPLES])]\n",
        "\n",
        "y_actual_subset = y_actual_phi[:MAX_SAMPLES]\n",
        "y_pred_subset = y_pred_phi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myjoBQf-09k4"
      },
      "outputs": [],
      "source": [
        "show_metrics(y_actual_subset, y_pred_subset, \"Few shot learning\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# okay with langchain then\n",
        "\n",
        "%pip install -q langchain"
      ],
      "metadata": {
        "id": "hB4CKe5o9kAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langchain_community"
      ],
      "metadata": {
        "id": "842DASJsK7C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langchain_huggingface"
      ],
      "metadata": {
        "id": "ROvnPqBQL6OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "4Rjk9fscHsHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is to help debugging.\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
      ],
      "metadata": {
        "id": "soNzIo8zODur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lc_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"author1\", \"author2\", \"author1_examples\", \"author2_examples\", \"text_to_classify\"],\n",
        "    template=prompt_template\n",
        ")"
      ],
      "metadata": {
        "id": "RxL41MyeILsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "\n",
        "# llm = HuggingFacePipeline.from_model_id(\n",
        "#     model_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
        "#     task=\"text-generation\",\n",
        "#     pipeline_kwargs={\"max_new_tokens\": 10},\n",
        "# )\n",
        "\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "#model_id=\"microsoft/Phi-3-mini-4k-instruct\"\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "#model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "pipe = pipeline(\n",
        "    \"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=10, device=device\n",
        ")\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n"
      ],
      "metadata": {
        "id": "vZ7DRrknIUy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cnt, (idx, sample) in enumerate(samples.iterrows()):\n",
        "    print(f\"Example {cnt+1}:\")\n",
        "    #print(f\"Text: {sample['text']}\")\n",
        "\n",
        "\n",
        "    #print(f\"Text: {sample['text']}\")\n",
        "    print(f\"Actual: {sample['label']}\")\n",
        "\n",
        "    prompt = lc_prompt_template.format(\n",
        "          author1=\"emerson\",\n",
        "          author2=\"thoreau\",\n",
        "          author1_examples=\"\\n\".join(emerson_samples_array), # Join examples into a single string\n",
        "          author2_examples=\"\\n\".join(thoreau_samples_array),\n",
        "          text_to_classify=sample['text']\n",
        "      )\n",
        "\n",
        "    predicted_label = llm.invoke(prompt)\n",
        "    print(f\"Prediction: {predicted_label}\")\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3Yad3N02I_9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EysXinZNMGIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7J5ZHi6wR2wP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}